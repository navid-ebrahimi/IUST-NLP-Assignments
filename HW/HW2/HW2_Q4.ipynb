{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8XI8WSJo9Sh"
      },
      "source": [
        "1.Submit a Google Colab notebook containing your completed code and experimentation results.\n",
        "\n",
        "2.Include comments and explanations in your code to help understand the implemented logic.\n",
        "\n",
        "**Additional Notes:**\n",
        "*   Ensure that the notebook runs successfully in Google Colab.\n",
        "*   Document any issues encountered during experimentation and how you addressed them.\n",
        "\n",
        "**Grading:**\n",
        "*   Each task will be graded out of the specified points.\n",
        "*   Points will be awarded for correctness, clarity of code, thorough experimentation, and insightful analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoUu86p1Or1n"
      },
      "source": [
        "# Prediction-Based Word Vectors\n",
        "\n",
        "more recently prediction-based word vectors have demonstrated better performance, such as word2vec and GloVe (which also utilizes the benefit of counts). Here, we shall explore the embeddings produced by GloVe.\n",
        "\n",
        "Then run the following cells to load the GloVe vectors into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvpYg_7pODYJ",
        "outputId": "96bdc5ba-4052-47e2-81d7-7d5b0251640f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 252.1/252.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "import pprint\n",
        "import numpy as np\n",
        "wv_from_bin = api.load(\"glove-wiki-gigaword-200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFfCOLUsSSuS"
      },
      "source": [
        "### Words with Multiple Meanings\n",
        "Polysemes and homonyms are words that have more than one meaning (see this [wiki page](https://en.wikipedia.org/wiki/Polysemy) to learn more about the difference between polysemes and homonyms ). Find a word with *at least two different meanings* such that the top-10 most similar words (according to cosine similarity) contain related words from *both* meanings. For example, \"leaves\" has both \"go_away\" and \"a_structure_of_a_plant\" meaning in the top 10, and \"scoop\" has both \"handed_waffle_cone\" and \"lowdown\". You will probably need to try several polysemous or homonymic words before you find one.\n",
        "\n",
        "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain **one** of the meanings of the words)?\n",
        "\n",
        "**Note**: You should use the `wv_from_bin.most_similar(word)` function to get the top 10 similar words. This function ranks all other words in the vocabulary with respect to their cosine similarity to the given word. For further assistance, please check the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar)__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAr09U-xSSuT"
      },
      "outputs": [],
      "source": [
        "### CODE HERE\n",
        "def get_similar_words(model, word, top_n=10):\n",
        "    # Get the top 10 most similar words to the input word\n",
        "    try:\n",
        "        similar_words = model.most_similar(word, topn=top_n)\n",
        "        return [sw[0] for sw in similar_words]\n",
        "    except KeyError:\n",
        "        return [\"Word not in model's vocabulary\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_similar_words(wv_from_bin, \"wolf\", top_n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfu2c0ZD6yEe",
        "outputId": "68c772c3-eb74-4071-9962-e5fee33ca71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bear',\n",
              " 'dog',\n",
              " 'lion',\n",
              " 'grizzly',\n",
              " 'wolves',\n",
              " 'coyote',\n",
              " 'mankowitz',\n",
              " 'cub',\n",
              " 'hunter',\n",
              " 'hunt']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The issue you're describing is a known limitation of Word2Vec and similar word embedding models. These models represent each word as a single vector in a high-dimensional space, where the vector's position is determined by the word's context in the training corpus. The model learns to place words with similar meanings close together in this space.\n",
        "\n",
        "However, this approach doesn't handle polysemy or homonymy well. Polysemous words have multiple related meanings, while homonyms are words that are spelled and pronounced the same way but have different meanings. Since Word2Vec represents each word as a single vector, it can't capture these multiple meanings. Instead, it tends to average them, resulting in a vector that might not accurately represent any of the word's meanings.\n",
        "\n",
        "For example, consider the word \"bank\". It could mean a financial institution, or the side of a river. In Word2Vec, these two meanings would be conflated into a single vector. Depending on the contexts in which \"bank\" appeared in the training corpus, the resulting vector might be closer to words related to finance, or to words related to geography, or it might not be particularly close to either.\n",
        "\n",
        "There are more advanced models, like BERT or ELMo, that can handle polysemy and homonymy better. These models represent words as functions of their context, so they can generate different vectors for the same word in different contexts. However, they're also more complex and computationally intensive than Word2Vec."
      ],
      "metadata": {
        "id": "e71q2mFW7PqX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdQ018tjSSuT"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfeW-eK9SSuU"
      },
      "source": [
        "### Synonyms & Antonyms\n",
        "\n",
        "When considering Cosine Similarity, it's often more convenient to think of Cosine Distance, which is simply 1 - Cosine Similarity.\n",
        "\n",
        "Find three words $(w_1,w_2,w_3)$ where $w_1$ and $w_2$ are synonyms and $w_1$ and $w_3$ are antonyms, but Cosine Distance $(w_1,w_3) <$ Cosine Distance $(w_1,w_2)$.\n",
        "\n",
        "As an example, $w_1$=\"happy\" is closer to $w_3$=\"sad\" than to $w_2$=\"cheerful\". Please find a different example that satisfies the above. Once you have found your example, please give a possible explanation for why this counter-intuitive result may have happened.\n",
        "\n",
        "You should use the the `wv_from_bin.distance(w1, w2)` function here in order to compute the cosine distance between two words. Please see the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance)__ for further assistance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwlpPjpHSSuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9c44ab-d1c2-493a-9198-9b7fb1d1f420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms big, large have cosine distance: 0.3340132236480713\n",
            "Antonyms big, small have cosine distance: 0.3511464595794678\n"
          ]
        }
      ],
      "source": [
        "w1 = \"big\"\n",
        "w2 = \"large\"\n",
        "w3 = \"small\"\n",
        "w1_w2_dist = wv_from_bin.distance(w1, w2)\n",
        "w1_w3_dist = wv_from_bin.distance(w1, w3)\n",
        "\n",
        "print(\"Synonyms {}, {} have cosine distance: {}\".format(w1, w2, w1_w2_dist))\n",
        "print(\"Antonyms {}, {} have cosine distance: {}\".format(w1, w3, w1_w3_dist))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIHjTFMSSuV"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxIDq26zSSuW"
      },
      "source": [
        "### Analogies with Word Vectors\n",
        "Word vectors have been shown to *sometimes* exhibit the ability to solve analogies.\n",
        "\n",
        "As an example, for the analogy \"man : grandfather :: woman : x\" (read: man is to grandfather as woman is to x), what is x?\n",
        "\n",
        "In the cell below, we show you how to use word vectors to find x using the `most_similar` function from the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar)__. The function finds words that are most similar to the words in the `positive` list and most dissimilar from the words in the `negative` list. The answer to the analogy will have the highest cosine similarity (largest returned numerical value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0pC7H4VSSuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6875d41a-7cbe-4673-a506-7e89c01d43ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('grandmother', 0.7608445286750793),\n",
            " ('granddaughter', 0.7200808525085449),\n",
            " ('daughter', 0.7168302536010742),\n",
            " ('mother', 0.7151536345481873),\n",
            " ('niece', 0.7005682587623596),\n",
            " ('father', 0.6659887433052063),\n",
            " ('aunt', 0.6623408794403076),\n",
            " ('grandson', 0.6618767976760864),\n",
            " ('grandparents', 0.644661009311676),\n",
            " ('wife', 0.6445354223251343)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to answer the analogy -- man : grandfather :: woman : x\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'grandfather'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVv8I9WwSSuZ"
      },
      "source": [
        "Let $m$, $g$, $w$, and $x$ denote the word vectors for `man`, `grandfather`, `woman`, and the answer, respectively. Using **only** vectors $m$, $g$, $w$, and the vector arithmetic operators $+$ and $-$ in your answer, to what expression are we maximizing $x$'s cosine similarity?\n",
        "\n",
        "Hint: Recall that word vectors are simply multi-dimensional vectors that represent a word. It might help to draw out a 2D example using arbitrary locations of each vector. Where would `man` and `woman` lie in the coordinate plane relative to `grandfather` and the answer?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(A, B):\n",
        "    dot_product = np.dot(A, B)\n",
        "    norm_a = np.linalg.norm(A)\n",
        "    norm_b = np.linalg.norm(B)\n",
        "    return dot_product / (norm_a * norm_b)"
      ],
      "metadata": {
        "id": "xaZYjtM2v3V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "man_vec = wv_from_bin['man']\n",
        "grandfather_vec = wv_from_bin['grandfather']\n",
        "woman_vec = wv_from_bin['woman']\n",
        "\n",
        "x = woman_vec + (grandfather_vec - man_vec)\n",
        "\n",
        "vocab = wv_from_bin.key_to_index\n",
        "\n",
        "# Print the words\n",
        "sim_dict = {}\n",
        "for word in vocab:\n",
        "  sim_dict[word] = cosine_similarity(x, wv_from_bin[word])"
      ],
      "metadata": {
        "id": "xttCH5Lzqb6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(sim_dict, key=sim_dict.get)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vlsDQY38wnz_",
        "outputId": "5ac6f91e-ddf4-48dc-d826-163d08848884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grandmother'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUKBqtHSSuZ"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRgMca9SSua"
      },
      "source": [
        "### Finding Analogies\n",
        "a. For the previous example, it's clear that \"grandmother\" completes the analogy. But give an intuitive explanation as to why the `most_similar` function gives us words like \"granddaughter\", \"daughter\", or \"mother?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "because these words are **semantically similar** to \"grandmother\". Word embeddings capture semantic relationships between words, so words that are used in similar contexts will have similar vectors.\n",
        "\n",
        "In the case of \"grandmother\", \"granddaughter\", \"daughter\", and \"mother\", these words are often used in similar contexts as they all relate to family relationships and more specifically, female family members. Therefore, their vectors are close in the high-dimensional space, leading to high cosine similarity scores.\n",
        "\n",
        "`most_similar` function doesn't understand the specific relationship you're trying to capture (i.e., the gender-switched equivalent of \"grandfather\"). It simply returns words that have vectors close to the computed vector `x`. Hence, other family-related terms appear in the results."
      ],
      "metadata": {
        "id": "O02b1EAlyHqr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgYQXazQSSua"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9aAUXEISSub"
      },
      "source": [
        "b. Find an example of analogy that holds according to these vectors (i.e. the intended word is ranked top). In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy is complicated, explain why the analogy holds in one or two sentences.\n",
        "\n",
        "**Note**: You may have to try many analogies to find one that works!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhzQJMYYVSjf"
      },
      "outputs": [],
      "source": [
        "x, y, a, b = 'man', 'king', 'woman', 'queen'\n",
        "assert wv_from_bin.most_similar(positive=[a, y], negative=[x])[0][0] == b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3QlPqAwSSub"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwgcEywwSSuc"
      },
      "source": [
        "### Incorrect Analogy\n",
        "a. Below, we expect to see the intended analogy \"hand : glove :: foot : **sock**\", but we see an unexpected result instead. Give a potential reason as to why this particular analogy turned out the way it did?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-ykWoJoSSuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c6065a-f8e8-4d9d-bc03-bd41a955d316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('45,000-square', 0.4922032654285431),\n",
            " ('15,000-square', 0.4649604558944702),\n",
            " ('10,000-square', 0.4544755816459656),\n",
            " ('6,000-square', 0.44975775480270386),\n",
            " ('3,500-square', 0.444133460521698),\n",
            " ('700-square', 0.44257497787475586),\n",
            " ('50,000-square', 0.4356396794319153),\n",
            " ('3,000-square', 0.43486514687538147),\n",
            " ('30,000-square', 0.4330596923828125),\n",
            " ('footed', 0.43236875534057617)]\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(wv_from_bin.most_similar(positive=['foot', 'glove'], negative=['hand']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Frequency of word usage**: The words \"foot\" and \"glove\" might not co-occur as frequently as \"hand\" and \"glove\" in the training corpus. This could affect the learned relationships.\n",
        "\n",
        "2. **Multiple meanings**: Words can have multiple meanings. For example, \"foot\" can also refer to a unit of measurement, and \"glove\" can refer to a type of boxing equipment. If these meanings are more prevalent in the training corpus, the resulting vector might not capture the intended relationship.\n",
        "\n",
        "3. **Complexity of relationships**: The relationship between \"hand\" and \"glove\" might not be exactly parallel to the relationship between \"foot\" and \"sock\" in terms of usage, context, and semantics. For example, gloves might be discussed more often in the context of safety equipment, while socks might be discussed more often in the context of comfort or fashion."
      ],
      "metadata": {
        "id": "aesAu-qh06eI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn4ruS8MSSud"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gHyZt0SSud"
      },
      "source": [
        "b. Find another example of analogy that does *not* hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the **incorrect** value of b according to the word vectors (in the previous example, this would be **'45,000-square'**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_rlci42XQTw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "26e59197-850b-4a75-b437-6ed404fc670e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('days', 0.6118359565734863),\n",
            " ('week', 0.592682421207428),\n",
            " ('month', 0.5850773453712463),\n",
            " ('next', 0.563667356967926),\n",
            " ('first', 0.5591050386428833),\n",
            " ('trip', 0.552686333656311),\n",
            " ('last', 0.5418316125869751),\n",
            " ('weeks', 0.5370946526527405),\n",
            " ('eve', 0.5344699621200562),\n",
            " ('this', 0.5237874984741211)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-31107eb7d667>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv_from_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mwv_from_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "x, y, a, b = 'sun', 'day', 'moon', 'night'\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[a, y], negative=[x]))\n",
        "\n",
        "assert wv_from_bin.most_similar(positive=[a, y], negative=[x])[0][0] == b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4x0EHjeSSue"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvlycXN-SSuf"
      },
      "source": [
        "### Guided Analysis of Bias in Word Vectors\n",
        "\n",
        "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
        "\n",
        "Run the cell below, to examine (a) which terms are most similar to \"woman\" and \"profession\" and most dissimilar to \"man\", and (b) which terms are most similar to \"man\" and \"profession\" and most dissimilar to \"woman\". Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XggWA4MhSSuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf0ec73-e5c0-4d9d-c8b4-0051c0e31fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('reputation', 0.5250176787376404),\n",
            " ('professions', 0.5178037881851196),\n",
            " ('skill', 0.49046966433525085),\n",
            " ('skills', 0.49005505442619324),\n",
            " ('ethic', 0.4897659420967102),\n",
            " ('business', 0.4875852167606354),\n",
            " ('respected', 0.485920250415802),\n",
            " ('practice', 0.482104629278183),\n",
            " ('regarded', 0.4778572618961334),\n",
            " ('life', 0.4760662019252777)]\n",
            "\n",
            "[('professions', 0.5957457423210144),\n",
            " ('practitioner', 0.49884122610092163),\n",
            " ('teaching', 0.48292139172554016),\n",
            " ('nursing', 0.48211804032325745),\n",
            " ('vocation', 0.4788965880870819),\n",
            " ('teacher', 0.47160351276397705),\n",
            " ('practicing', 0.46937814354896545),\n",
            " ('educator', 0.46524327993392944),\n",
            " ('physicians', 0.4628995358943939),\n",
            " ('professionals', 0.4601394236087799)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell\n",
        "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be most dissimilar from.\n",
        "\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'profession'], negative=['woman']))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'profession'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gender bias in the word embeddings is reflected in the associations the model makes between the words “man”, “woman”, and “profession” and the other words it deems most similar.\n",
        "\n",
        "For the word pair “man” and “profession”, the model associates words like “business”, “respected”, and “regarded”. These words carry a certain connotation of authority, respect, and business acumen, which are traditionally associated with men in many societies.\n",
        "\n",
        "On the other hand, for the word pair “woman” and “profession”, the model associates words like “teaching”, “nursing”, “teacher”, and “educator”. These words are often associated with caregiving or educational roles, which are traditionally seen as ‘feminine’ professions in many societies.\n",
        "\n",
        "This difference in associations reflects a gender bias in the data the model was trained on. It’s important to note that these biases are not a reflection of reality or an endorsement of these stereotypes, but rather a reflection of the biases present in the text data the model was trained on. As such, it’s crucial to be aware of these biases when using word embeddings in applications, as they can inadvertently perpetuate harmful stereotypes."
      ],
      "metadata": {
        "id": "YSd9STAn2_s9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4g6KbsYSSuh"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxJmnS6lSSui"
      },
      "source": [
        "### Independent Analysis of Bias in Word Vectors\n",
        "\n",
        "Use the `most_similar` function to find another pair of analogies that demonstrates some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZoDheIfSSui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13ff8dd-15ef-4b7b-cdc7-a3c6d045230a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('physician', 0.6617421507835388),\n",
            " ('surgeon', 0.5713728070259094),\n",
            " ('doctors', 0.5704407691955566),\n",
            " ('medical', 0.564996600151062),\n",
            " ('him', 0.5392459034919739),\n",
            " ('dr.', 0.5354140996932983),\n",
            " ('himself', 0.5292457938194275),\n",
            " ('his', 0.5211162567138672),\n",
            " ('hospital', 0.5205545425415039),\n",
            " ('man', 0.505194365978241)]\n",
            "\n",
            "[('nurse', 0.6992564797401428),\n",
            " ('mother', 0.6033010482788086),\n",
            " ('woman', 0.6029850840568542),\n",
            " ('her', 0.5852972269058228),\n",
            " ('physician', 0.5735723376274109),\n",
            " ('pregnant', 0.5676814913749695),\n",
            " ('dr.', 0.5605944395065308),\n",
            " ('doctors', 0.5586872696876526),\n",
            " ('patient', 0.5518049001693726),\n",
            " ('hospital', 0.548409104347229)]\n"
          ]
        }
      ],
      "source": [
        "A = 'he'\n",
        "B = 'she'\n",
        "word = 'doctor'\n",
        "\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[A, word], negative=[B]))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[B, word], negative=[A]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this hypothetical output, you can see that when we ask for words similar to “he” and “doctor” but dissimilar to “she”, we get words like “surgeon” and “physician”, which are typically high-status roles in the medical field. On the other hand, when we ask for words similar to “she” and “doctor” but dissimilar to “he”, we get “nurse” as the top result, which is a role that has been historically female-dominated and is often perceived as having lower status than “doctor”. This could be seen as a reflection of gender bias in the data the model was trained on."
      ],
      "metadata": {
        "id": "dlq9Biv63oL_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGOlmtJoSSuj"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK2XVWzmSSuk"
      },
      "source": [
        "### Thinking About Bias\n",
        "\n",
        "a. Give one explanation of how bias gets into the word vectors. Briefly describe a real-world example that demonstrates this source of bias."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bias in word vectors often originates from the data they are trained on. Word embeddings are a type of machine learning model that are trained on large amounts of text data. If the text data contains biases, the model will learn and reproduce these biases.\n",
        "\n",
        "For example, if the training data frequently associates men with professions like “engineer” or “doctor” and women with roles like “nurse” or “teacher”, the word vectors will reflect these associations. This is because the model learns to predict words based on their context, and if certain words (like professions) are frequently found in the context of certain other words (like gendered pronouns), the model will learn to associate these words with each other.\n",
        "\n",
        "A real-world example of this can be seen in the use of word embeddings in job recommendation algorithms. If a job recommendation algorithm uses biased word embeddings, it might recommend high-paying, prestigious jobs to men more often than to women, simply because the word vectors associate words like “CEO” or “engineer” more closely with “he” than with “she”. This can perpetuate gender inequality in the job market. It’s therefore crucial to be aware of these biases and to develop methods to mitigate them when using word embeddings in real-world applications."
      ],
      "metadata": {
        "id": "_T-5jJ0u4Wyo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19pM85fCSSuk"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILYqJZ7ASSul"
      },
      "source": [
        "b. What is one method you can use to mitigate bias exhibited by word vectors?  Briefly describe a real-world example that demonstrates this method."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One method to mitigate bias exhibited by word vectors is called \"hard de-biasing\". This method involves identifying specific directions in the vector space that correspond to undesired biases (such as gender or race), and then adjusting the word vectors to remove these biases.\n",
        "\n",
        "For example, researchers at Stanford University used this method to reduce gender bias in word embeddings. They first identified a set of gender-neutral words (such as 'doctor' or 'engineer') that should not be associated with any particular gender. They then calculated the average difference between the vectors for male-associated words (such as 'man' or 'boy') and female-associated words (such as 'woman' or 'girl'). This difference was used to define the \"gender direction\" in the vector space.\n",
        "\n",
        "Next, they adjusted the vectors for the gender-neutral words to make them orthogonal (i.e., perpendicular) to the gender direction. This effectively removed any gender bias from these words, while preserving their other semantic properties.\n",
        "\n",
        "In a real-world example, this method could be used to reduce gender bias in a job recommendation system. By de-biasing the word vectors used by the system, it would be less likely to recommend certain jobs to men over women (or vice versa) based solely on their gender. This could help to promote more equitable hiring practices and reduce gender disparities in the workforce."
      ],
      "metadata": {
        "id": "rJGDaMw95cx-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJaAB7mSSul"
      },
      "source": [
        "\n",
        "### SOLUTION"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}