{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Q1: Probabilistic N-Gram Language Model(50 points)"
      ],
      "metadata": {
        "id": "a4NQTign_k_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "The objective of this question is to implement and experiment with an N-Gram language model using the Reuters dataset. The task involves building a probabilistic N-Gram model and creating a text generator based on the trained model with customizable parameters.\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "\n",
        "**1.Text Preprocessing (5 points):**\n",
        "*   Implement the preprocess_text function to perform necessary text preprocessing. You may use NLTK or other relevant libraries for this task. (Already provided, no modification needed)\n",
        "\n",
        "\n",
        "**2.Build Probabilistic N-Gram Model (15 points):**\n",
        "\n",
        "*   Implement the build_probabilistic_ngram_model function to construct a probabilistic N-Gram model from the Reuters dataset.\n",
        "\n",
        "\n",
        "**3.Generate Text with Customizable Parameters (15 points):**\n",
        "\n",
        "*   Implement the generate_text function to generate text given a seed text and the probabilistic N-Gram model.\n",
        "*   The function should have parameters for probability_threshold and min_length to customize the generation process.\n",
        "*   Ensure that the generation stops when either the specified min_length is reached or the probabilities fall below probability_threshold.\n",
        "\n",
        "\n",
        "**4.Experimentation and Parameter Tuning (5 points):**\n",
        "\n",
        "*   Use Google Colab to experiment with different values of n_value, probability_threshold, and min_length.\n",
        "Find the optimal parameters that result in coherent and meaningful generated text.\n",
        "*   Provide a detailed analysis of the impact of changing each parameter on the generated text's quality.\n",
        "*   Discuss any challenges faced during parameter tuning and propose potential improvements.\n",
        "\n",
        "\n",
        "**5.Results and Conclusion (10 points):**\n",
        "\n",
        "*   Summarize your findings and present the optimal parameter values for n_value, probability_threshold, and min_length.\n",
        "*   Discuss the trade-offs and considerations when selecting these parameters.\n",
        "*   Conclude with insights gained from the experimentation."
      ],
      "metadata": {
        "id": "zDKtnG-HAH1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import random\n",
        "import string\n",
        "from collections import defaultdict, Counter\n",
        "from gensim.models.fasttext import FastText\n",
        "import numpy as np\n",
        "\n",
        "# Download the Reuters dataset if not already downloaded\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "3NWXJy-T-Vd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77564c72-c940-410d-ec5d-e6875876589c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9IHxAbU0N80"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# This function preprocesses the input text by tokenizing it into sentences, converting all words to lower case,\n",
        "removing punctuation and non-alphabetic tokens, and then joining the words back into sentences and the sentences back into a text.\n",
        "\"\"\"\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    preprocessed_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence into words\n",
        "        tokens = word_tokenize(sentence)\n",
        "\n",
        "        # Convert to lower case\n",
        "        tokens = [word.lower() for word in tokens]\n",
        "\n",
        "        # Remove punctuation and non-alphabetic tokens\n",
        "        words = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "        # Join the words back into a sentence and add to the list\n",
        "        words.append('.')\n",
        "        preprocessed_sentences.append(' '.join(words))\n",
        "\n",
        "    # Join the sentences back into a text\n",
        "    preprocessed_text = ' '.join(preprocessed_sentences)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "\"\"\"\n",
        "# This function builds a probabilistic n-gram model from the given corpus.\n",
        "It tokenizes the text into sentences, then into words, and creates n-grams from these words.\n",
        "It then calculates the probabilities of each word following a given (n-1)-gram.\n",
        "\"\"\"\n",
        "# Function to build a probabilistic n-gram model\n",
        "def build_probabilistic_ngram_model(corpus, n):\n",
        "    # Create a dictionary to hold the n-gram model\n",
        "    model = defaultdict(Counter)\n",
        "\n",
        "    # Populate the dictionary with counts of n-grams and (n-1)-grams\n",
        "    for text in corpus:\n",
        "      sentences = sent_tokenize(text)\n",
        "      preprocessed_sentences = []\n",
        "      for sentence in sentences:\n",
        "        tokens = ['<s>'] * (n - 1) + word_tokenize(sentence)\n",
        "        n_grams = list(ngrams(tokens, n+1))\n",
        "        for n_gram in n_grams:\n",
        "            n_1_gram = n_gram[:-1]\n",
        "            next_word = n_gram[-1]\n",
        "            model[n_1_gram][next_word] += 1\n",
        "\n",
        "    # Calculate the probabilities\n",
        "    for n_1_gram, next_words in model.items():\n",
        "        total_count = sum(next_words.values())\n",
        "        for next_word, count in next_words.items():\n",
        "            model[n_1_gram][next_word] = count / total_count\n",
        "\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "This function generates text using the probabilistic n-gram model. It tokenizes the seed text, generates words until it reaches the minimum length,\n",
        "gets the probabilities of the next word given the context, and stops generating if the probability of the next word is below the threshold.\n",
        "It then joins the generated words into a string.\n",
        "\"\"\"\n",
        "# Function to generate text using the probabilistic n-gram model with stop criteria\n",
        "def generate_text(model, seed_text, n, probability_threshold=0.1, min_length=10):\n",
        "    # Tokenize the seed text\n",
        "    seed_text = seed_text.lower()\n",
        "    seed_tokens = word_tokenize(seed_text)\n",
        "    seed_tokens = ['<s>'] * (n - 1) + seed_tokens[:n]\n",
        "    # Generate words until we reach the minimum length\n",
        "    generated_words = seed_tokens\n",
        "    num = 0\n",
        "    while True:\n",
        "        # Get the last n words as the context\n",
        "        context = tuple(generated_words[-n:])\n",
        "        # Get the probabilities of the next word given the context\n",
        "        next_word_probs = model[context]\n",
        "        if not next_word_probs:\n",
        "            # If next_word_probs is empty, use n-1gram, n-2gram, ... until 1gram\n",
        "            for i in range(n-1, 0, -1):\n",
        "                context = tuple(generated_words[-i:])\n",
        "                model = build_probabilistic_ngram_model(preprocessed_corpus, i)\n",
        "                next_word_probs = model[context]\n",
        "                if next_word_probs:\n",
        "                    break\n",
        "            if not next_word_probs:\n",
        "                next_word = random.choice(list(model.keys()))[0]\n",
        "            else:\n",
        "                next_word = random.choices(list(next_word_probs.keys()), weights=list(next_word_probs.values()))[0]\n",
        "        else:\n",
        "            next_word = random.choices(list(next_word_probs.keys()), weights=list(next_word_probs.values()))[0]\n",
        "            # If the probability of the next word is below the threshold, stop generating\n",
        "        if next_word_probs[next_word] < probability_threshold and num >= min_length:\n",
        "            break\n",
        "\n",
        "        # Add the next word to the generated words\n",
        "        generated_words.append(next_word)\n",
        "        num += 1\n",
        "    # Join the words into a string\n",
        "    generated_words = generated_words[n-1:]\n",
        "    generated_text = ' '.join(generated_words)\n",
        "    return generated_text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Reuters dataset\n",
        "corpus = [reuters.raw(file_id) for file_id in reuters.fileids()]\n",
        "# Preprocess the entire corpus\n",
        "preprocessed_corpus = [preprocess_text(text) for text in corpus]"
      ],
      "metadata": {
        "id": "eVVMe_s59Ngd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose an n for the n-gram model\n",
        "n_value = 3  # You may change this value\n",
        "\n",
        "# Build the probabilistic n-gram model\n",
        "probabilistic_ngram_model = build_probabilistic_ngram_model(preprocessed_corpus, n_value)"
      ],
      "metadata": {
        "id": "iCil0mC_DX21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the text generator\n",
        "seed_text = \"Inflation is\"\n",
        "generated_text = generate_text(probabilistic_ngram_model, seed_text, n_value, probability_threshold=0.1, min_length=10)\n",
        "print(f\"Generated Text: {generated_text}\")"
      ],
      "metadata": {
        "id": "n-4WP7IC9Q7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49797266-ef60-4481-cdde-5494a8629c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text: inflation is expected to exceed 125 mln dlrs . 2,239 dlrs for\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 4**"
      ],
      "metadata": {
        "id": "nGdTG2jCm5zG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_value = [2, 3, 4]\n",
        "probability_threshold = [0.05, 0.1, 0.2]\n",
        "min_length = [10,15,20]\n",
        "\n",
        "for val in n_value:\n",
        "  for prob in probability_threshold:\n",
        "    for length in min_length:\n",
        "      generated_text = generate_text(probabilistic_ngram_model, seed_text, val, probability_threshold=prob, min_length=length)\n",
        "      print(f'n_value={val}, probability_threshold={prob}, min_length={length}: generated_text={generated_text}')\n",
        "      print('-----------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJPJhbosm5U8",
        "outputId": "6bb10661-8855-425e-94f9-f6cdbf40195f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_value=2, probability_threshold=0.05, min_length=10: generated_text=inflation is perceived target markets and fairer treatment and the gatt and\n",
            "-----------------\n",
            "n_value=2, probability_threshold=0.05, min_length=15: generated_text=inflation is payable april and beet crop soybeans 610 billion dlrs . 193,193 dlrs jan 31 against\n",
            "-----------------\n",
            "n_value=2, probability_threshold=0.05, min_length=20: generated_text=inflation is a lb effective immediately . s.a.y said any pubilic policy review world 's customers the economy ministers are likely to\n",
            "-----------------\n",
            "n_value=2, probability_threshold=0.1, min_length=10: generated_text=inflation is rising . 5,896,322 vs 43.1 billion dlrs a canadian-led oil\n",
            "-----------------\n",
            "n_value=2, probability_threshold=0.1, min_length=15: generated_text=inflation is under-utilised because of 297,000 dlrs per day bpd from depths of its world 's new york\n",
            "-----------------\n",
            "n_value=2, probability_threshold=0.1, min_length=20: generated_text=inflation is expected he said `` credits of its estate joint balance of real estate developer donald guinn also sparked an argentine\n",
            "-----------------\n",
            "n_value=2, probability_threshold=0.2, min_length=10: generated_text=inflation is the sunlight needed . 54,576 in an agrreement regarding the\n",
            "-----------------\n",
            "n_value=2, probability_threshold=0.2, min_length=15: generated_text=inflation is the discovery well `` he said . lifted its shareholder approval . conneticut chartered bank\n",
            "-----------------\n",
            "n_value=2, probability_threshold=0.2, min_length=20: generated_text=inflation is the national westminster bank 's recent stock form nov 17 and its stake in and `` we want it .\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.05, min_length=10: generated_text=inflation is expected to have little if any effect on the government 's\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.05, min_length=15: generated_text=inflation is expected to decline to 480,000 tonnes shipped weight in 1987 and a very moderate but positive contribution from private domestic demand .\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.05, min_length=20: generated_text=inflation is expected to reach around 2.5 mln stg six months to february against 17.6 pct in january while sales at eating and drinking places increased 1.5 pct after falling 0.3 pct in february\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.1, min_length=10: generated_text=inflation is expected to boost japan 's unemployment rate was down from 80.2 pct because imports from ecuador fell to 21,110 tonnes in 1986 from\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.1, min_length=15: generated_text=inflation is expected to be maioled this quarter . 131,000 dlrs vs 86,000 dlrs in 1985 while the\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.1, min_length=20: generated_text=inflation is running at an average yield of public paper is already nearing last year 's 2.5 pct growth rate finance minister michael wilson said large inflows of capital into canada principally into the country .\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.2, min_length=10: generated_text=inflation is running at about 20,000 will continue . lest it give foreign investors\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.2, min_length=15: generated_text=inflation is running at about three p.m. local 1900 gmt at the treasury . counterparty into one single agreement to\n",
            "-----------------\n",
            "n_value=3, probability_threshold=0.2, min_length=20: generated_text=inflation is expected to be required to be shipped within 12 mths was 63.0 mln dlrs on sale of equity holdings results in u.s. funds rather than sterling beginning from jan 1 1987 company changed oil and gas\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.05, min_length=10: generated_text=inflation is expected to be completed in june they said . company-owned bojangles restaurants and is in competition with the u.s. and\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.05, min_length=15: generated_text=inflation is expected to reduce its foreign debt was worked out by coalition partners this month was an `` important step in the affiliation process which began in 1984 comes from two state trading firms -- the state trading corp stc and the minerals and metals trading corp signed its first long-term export agreement with the united states\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.05, min_length=20: generated_text=inflation is expected to consistently exceed the standard and poor 's corp should not be taken as an indication of his management style and priorities .\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.1, min_length=10: generated_text=inflation is expected to partially reopen next week a virtual impossibility they said .\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.1, min_length=15: generated_text=inflation is expected to propose a new formula will be used to boost production by injecting gas in the early\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.1, min_length=20: generated_text=inflation is expected to unveil expansionary budget south africa is expected to award export licences at 134.75 ecu rebate brussels trade ec grants 5,000 tonnes soft wheat export licences at a maximum rebate of 44.819 .\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.2, min_length=10: generated_text=inflation is expected to weaken this year adding internally generated funds will cover all of its\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.2, min_length=15: generated_text=inflation is expected to be formally adopted tomorrow a new international cocoa agreement icca for which buffer stock rules\n",
            "-----------------\n",
            "n_value=4, probability_threshold=0.2, min_length=20: generated_text=inflation is expected to weaken this year adding new worries to an already serious poverty outlook economic analysts said . arv ses flat 1st qtr per share net compared with 59 cts last year .\n",
            "-----------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analyze**"
      ],
      "metadata": {
        "id": "4WMMrVwoiTbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For **n-gram**: the higher the value of n, the more meaningful the output will be. which is the reason for considering more words before itself. For example, the word \"inflation\", which is the subject of the sentence, has a lot of meaning. Now, if we take n equal to 2, for example, we will not affect it in the next selections. For this reason, the bigger n is, the more meaningful the sentence is. The larger n is, the number of special cases increases, in such cases, n-i is used.\n",
        "\n",
        "**For probability_threshold**: the higher this value is, the shorter the sentence is because the probability of the next word needs to be a larger number.\n",
        "\n",
        "**Min Length**: Because less than 10 sentences usually cannot convey the meaning completely, usually 10 is a suitable number for this task."
      ],
      "metadata": {
        "id": "zlvXmufhiQWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q2: Sentiment Analysis with Naive Bayes Classifier(50 Points)"
      ],
      "metadata": {
        "id": "dZ3XzDx7JUNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "You are tasked with implementing a Naive Bayes classifier for sentiment analysis. The provided code is incomplete, and your goal is to complete the missing parts. Additionally, you should train the classifier on a small dataset and analyze its performance.\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1.**Complete the Code (35 points)**: Fill in the missing parts in the provided Python code for the Naive Bayes classifier. Pay special attention to the `extract_features` function.\n",
        "\n",
        "2.**Train and Test**: Train the Naive Bayes classifier on the training data and test it on a separate test set. Evaluate the accuracy of the classifier.\n",
        "\n",
        "3.**Analysis (15 points)**: Discuss the results. Identify any misclassifications and try to understand why the classifier may fail in those cases. Provide examples of sentences that were not predicted correctly and explain possible reasons.\n"
      ],
      "metadata": {
        "id": "NMuVkjW2XfAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import string\n",
        "from collections import defaultdict\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import movie_reviews\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "M68XJubdKeDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6929c403-0394-4bdd-be53-7eb9097a47c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(tokens):\n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Perform stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "KSLo4_JoUcax"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, classes):\n",
        "        # Initialize the class labels and the dictionaries to hold class and feature probabilities\n",
        "        self.classes = classes\n",
        "        self.class_probs = defaultdict(float)\n",
        "        self.feature_probs = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "    def train(self, training_data):\n",
        "        # This function trains the Naive Bayes Classifier\n",
        "        # Initialize counters for classes and features\n",
        "        alpha = 1\n",
        "        class_counts = defaultdict(int)\n",
        "        feature_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        # Count features and classes\n",
        "        for features, class_ in training_data:\n",
        "            # Extract useful tokens from the dataset using the get_features function\n",
        "            features = get_features(features)\n",
        "            # Increment the count of the current class\n",
        "            class_counts[class_] += 1\n",
        "            # Increment the count of the current feature for the current class\n",
        "            for feature in features:\n",
        "                feature_counts[feature][class_] += 1\n",
        "\n",
        "        # Calculate probabilities\n",
        "        for class_, count in class_counts.items():\n",
        "            # Calculate the probability of each class\n",
        "            self.class_probs[class_] = count / len(training_data)\n",
        "            # Calculate the sum of feature counts for the current class\n",
        "            x = sum(feature_counts[feature][class_] for feature, counts in feature_counts.items())\n",
        "            # Calculate the probability of each feature given each class\n",
        "            for feature in feature_counts:\n",
        "                self.feature_probs[feature][class_] = (feature_counts[feature][class_]+alpha) / (x+alpha*len(feature_counts))\n",
        "\n",
        "    def classify(self, features):\n",
        "        # This function classifies a given set of features\n",
        "        # Initialize the dictionary to hold class probabilities\n",
        "        class_probs = defaultdict(float)\n",
        "        for class_ in self.classes:\n",
        "            # Calculate the log probability of each class\n",
        "            class_probs[class_] = math.log(self.class_probs[class_])\n",
        "            # Extract useful tokens from the features using the get_features function\n",
        "            for feature in get_features(features):\n",
        "                # If the feature is in the feature probabilities dictionary, add its log probability to the class probability\n",
        "                if feature in self.feature_probs:\n",
        "                    class_probs[class_] += math.log(self.feature_probs[feature][class_])\n",
        "\n",
        "        # Return the class with the highest probability\n",
        "        return max(class_probs, key=class_probs.get)\n"
      ],
      "metadata": {
        "id": "m2Whvjy_Jq8n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the movie reviews dataset from NLTK\n",
        "data = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "random.shuffle(data)\n",
        "# Shuffle the dataset for randomness\n",
        "random.shuffle(data)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(data) * split_ratio)\n",
        "train_set = data[:split_index]\n",
        "test_set = data[split_index:]\n",
        "# Train the Naive Bayes classifier\n",
        "classes = set(sentiment for _, sentiment in train_set)\n",
        "classifier = NaiveBayesClassifier(classes)\n",
        "classifier.train(train_set)\n",
        "\n",
        "def calculate_accuracy(dataset, dataset_type):\n",
        "    # Test the classifier on the testing set\n",
        "    correct_predictions = 0\n",
        "    for example in dataset:\n",
        "        tokens, true_sentiment = example\n",
        "        features = get_features(tokens)\n",
        "        predicted_sentiment = classifier.classify(features)\n",
        "        if predicted_sentiment == true_sentiment:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / len(dataset)\n",
        "    print(f\"{dataset_type} Accuracy: {accuracy}\")\n",
        "\n",
        "calculate_accuracy(train_set, 'Train')\n",
        "calculate_accuracy(test_set, 'Test')"
      ],
      "metadata": {
        "id": "j2jeyI6nKooE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649c068b-6913-4dde-b06e-3c667f4b94eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.964375\n",
            "Test Accuracy: 0.8175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = ['the', 'weather', 'is', 'not', 'bad']\n",
        "features = get_features(tokens)\n",
        "classifier_var = classifier.classify(features)\n",
        "classifier_var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "41axo9L5uS-5",
        "outputId": "9c5fcf95-91c4-4efe-debf-6e0d799c607b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analyze:**"
      ],
      "metadata": {
        "id": "PBsCcCD5iyzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the problem is a bayes problem, it is not possible to reach 100% accuracy because sometimes the word order is effective if bayes ignores this case. Sometimes in Bayes, only the word is important, not the structure of the sentence. Bigram can be used to solve this issue.\n",
        "\n",
        "For example, the sentence \"the weather is not bad\" is a negative sentence, but because bayes only pays attention to words and the word \"bad\" is present in it, it predicts this sentence positively."
      ],
      "metadata": {
        "id": "qST3UolkiwLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Submission Instructions:\n"
      ],
      "metadata": {
        "id": "Nfl8UA42Gqjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Submit a Google Colab notebook containing your completed code and experimentation results.\n",
        "\n",
        "2.Include comments and explanations in your code to help understand the implemented logic.\n",
        "\n",
        "3.Clearly present the results of your parameter tuning in the notebook.\n",
        "\n",
        "4.Provide a brief summary of your findings and insights in the conclusion section.\n",
        "\n",
        "**Additional Notes:**\n",
        "*   Ensure that the notebook runs successfully in Google Colab.\n",
        "*   Experiment with various seed texts to showcase the diversity of generated text.\n",
        "*   Document any issues encountered during experimentation and how you addressed them.\n",
        "\n",
        "**Grading:**\n",
        "*   Each task will be graded out of the specified points.\n",
        "*   Points will be awarded for correctness, clarity of code, thorough experimentation, and insightful analysis."
      ],
      "metadata": {
        "id": "75kVTQX6GsCn"
      }
    }
  ]
}